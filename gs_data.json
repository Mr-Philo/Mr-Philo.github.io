{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "gu_oKFIAAAAJ&hl", "source": "AUTHOR_PROFILE_PAGE", "name": "Ruizhe Wang", "affiliation": "PhD student, University of Science and Technology of China", "organization": 8123924430127665534, "interests": ["LLM Pretraining"], "email_domain": "@mail.ustc.edu.cn", "homepage": "https://mr-philo.github.io/", "citedby": 114, "publications": {"gu_oKFIAAAAJ:u5HHmVD_uO8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Fp8-lm: Training fp8 large language models", "pub_year": "2023"}, "filled": false, "author_pub_id": "gu_oKFIAAAAJ:u5HHmVD_uO8C", "num_citations": 85, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11385170037295792216,6966657190251700290", "cites_id": ["11385170037295792216", "6966657190251700290"]}, "gu_oKFIAAAAJ:9yKSN-GCB0IC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Optimizing large language model training using fp4 quantization", "pub_year": "2025"}, "filled": false, "author_pub_id": "gu_oKFIAAAAJ:9yKSN-GCB0IC", "num_citations": 28, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4874757437542497077", "cites_id": ["4874757437542497077"]}, "gu_oKFIAAAAJ:WF5omc3nYNoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Training Matryoshka Mixture-of-Experts for Elastic Inference-Time Expert Utilization", "pub_year": "2025"}, "filled": false, "author_pub_id": "gu_oKFIAAAAJ:WF5omc3nYNoC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6716328857493869022", "cites_id": ["6716328857493869022"]}, "gu_oKFIAAAAJ:LkGwnXOMwfcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Sigma-Moe-Tiny Technical Report", "pub_year": "2025"}, "filled": false, "author_pub_id": "gu_oKFIAAAAJ:LkGwnXOMwfcC", "num_citations": 0}, "gu_oKFIAAAAJ:_FxGoFyzp5QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SIGMA: An AI-Empowered Training Stack on Early-Life Hardware", "pub_year": "2025"}, "filled": false, "author_pub_id": "gu_oKFIAAAAJ:_FxGoFyzp5QC", "num_citations": 0}, "gu_oKFIAAAAJ:ufrVoPGSRksC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Recycling Pretrained Checkpoints: Orthogonal Growth of Mixture-of-Experts for Efficient Large Language Model Pre-Training", "pub_year": "2025"}, "filled": false, "author_pub_id": "gu_oKFIAAAAJ:ufrVoPGSRksC", "num_citations": 0}, "gu_oKFIAAAAJ:d1gkVwhDpl0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Method and system of generating customized three-dimensional images", "pub_year": "2024"}, "filled": false, "author_pub_id": "gu_oKFIAAAAJ:d1gkVwhDpl0C", "num_citations": 0}, "gu_oKFIAAAAJ:u-x6o8ySG0sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Method and system of generating customized images", "pub_year": "2024"}, "filled": false, "author_pub_id": "gu_oKFIAAAAJ:u-x6o8ySG0sC", "num_citations": 0}}, "citedby5y": 114, "hindex": 2, "hindex5y": 2, "i10index": 2, "i10index5y": 2, "cites_per_year": {"2023": 1, "2024": 23, "2025": 84, "2026": 5}, "updated": "2026-02-06 07:02:37.948279"}